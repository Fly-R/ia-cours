# Projet SMART - Rapport

L‚Äôobjectif du projet SMART est d√©velopper un projet en Python capable d‚Äôutiliser la
Computer Vision pour reconnaitre automatiquement un ensemble d√©fini de produits. La
d√©tection se fera soit sur une image, soit sur une vid√©o, soit sur le flux cam√©ra d‚Äôun
ordinateur en temps r√©el.

## Les premiers tests

### Experiment n¬∞1 ([real_exp_10_yolo_s](https://app.picsellia.com/0192f6db-86b6-784c-80e6-163debb242d5/project/01936425-704a-7d93-b1bb-1b1641812ba4/experiment/0194d7c2-3718-76f0-b280-26eb28edd7cc/))

#### Param√®tres de l'entrainement
- Mod√®le : YOLOv11-S
- epochs : 400
- Param√®tres par d√©faut

#### R√©sultats : 
| M√©trique   | Valeur finale | Maximum atteint pendant l'entra√Ænement   |
|------------|---------------|------------------------------------------|
| Pr√©cision  | 0.84          | 0.89                                     |
| Recall     | 0.65          | 0.70                                     |
| mAP50      | 0.76          | 0.77                                     |
| mAP50-95   | 0.62          | -                                        |

Les diff√©rentes loss pendant le training : 

| box_loss                                                         | cls_loss                                                         | dfl_loss                                                         |
|------------------------------------------------------------------|------------------------------------------------------------------|------------------------------------------------------------------|
| <img src="img/exp1/box_loss.png" width="350" height="300"> | <img src="img/exp1/cls_loss.png" width="350" height="300"> | <img src="img/exp1/dfl_loss.png" width="350" height="300"> |


Une analyse plus d√©taill√©e de la box loss montre que la validation loss commence √† diverger de la training loss autour 
de la 30√®me epoch. Cela sugg√®re que le mod√®le commence √† sur-apprendre, et qu'un arr√™t pr√©coce pourrait √™tre envisag√© 
pour √©viter le sur-ajustement.

<img src="img/exp1/box_loss_annoted.png" width="350" height="300">

### Experiment n¬∞2 ([real_exp_11_yolo_l](https://app.picsellia.com/0192f6db-86b6-784c-80e6-163debb242d5/project/01936425-704a-7d93-b1bb-1b1641812ba4/experiment/0194e272-62f8-7d4b-82ce-21cd06f6100e/))

#### Param√®tres de l'entrainement
- Mod√®le : YOLOv11-L
- epochs : 50
- Param√®tres par d√©faut

Les diff√©rentes loss pendant le training : 

| box_loss                                                   | cls_loss                                                   | dfl_loss                                                   |
|------------------------------------------------------------|------------------------------------------------------------|------------------------------------------------------------|
| <img src="img/exp2/box_loss.png" width="350" height="300"> | <img src="img/exp2/cls_loss.png" width="350" height="300"> | <img src="img/exp3/dfl_loss.png" width="350" height="300"> |

On a choisi de tester ce mod√®le (un peu pour le fun) car c'est un mod√®le assez lourd. Comme dans l'experiment pr√©c√©dente,
on a vu qu'il n'√©tait pas forc√©ment n√©cessaire de faire beaucoup d'epochs, il serait possible de train celui "rapidement".

Finalement, le training a √©t√© plut√¥t long et les r√©sultats ne sont pas tr√®s bons. La pr√©cision et le recall sont tr√®s faibles 
et meriteraient de faire plus d'epochs mais le cout en ressource est trop important pour le faire donc on peut laisser 
tomber ce mod√®le.

La matrice de confusion est aussi catastrophique

<img src="img/exp2/conf_matrix.png" width="350" height="300"> 


### Experiment n¬∞3 ([real_exp_12_yolo_m](https://app.picsellia.com/0192f6db-86b6-784c-80e6-163debb242d5/project/01936425-704a-7d93-b1bb-1b1641812ba4/experiment/0194e4dd-d8d8-7061-ab50-9b34e8e59523/))

#### Param√®tres de l'entrainement
- Mod√®le : YOLOv11-M
- epochs : 100
- Param√®tres par d√©faut

#### R√©sultats : 
| M√©trique   | Valeur finale | Maximum atteint pendant l'entra√Ænement |
|------------|---------------|----------------------------------------|
| Pr√©cision  | 0.72          | 0.80 (12√®me epoch)                     |
| Recall     | 0.42          | 0.49 (90√®me epoch)                     |
| mAP50      | 0.53          | -                                      |
| mAP50-95   | 0.40          | -                                      |

Les diff√©rentes loss pendant le training : 

| box_loss                                                   | cls_loss                                                   | dfl_loss                                                   |
|------------------------------------------------------------|------------------------------------------------------------|------------------------------------------------------------|
| <img src="img/exp3/box_loss.png" width="350" height="300"> | <img src="img/exp3/cls_loss.png" width="350" height="300"> | <img src="img/exp3/dfl_loss.png" width="350" height="300"> |  

On a choisi le mod√®le M qui semble √™tre le plus prometteur. Les entra√Ænements pr√©c√©dents avec ce mod√®le ont donn√© 
de bons r√©sultats.
Dans un premier temps, on a test√© avec 100 epochs pour observer les performances et envisager des am√©liorations ult√©rieures.

Toutes les validation loss approchent leurs training loss, mais la pr√©cision et le recall restent faibles et en pleine 
croissance. Il pourrait √™tre pertinent de reprendre ce mod√®le pour lancer 100 nouvelles epochs et tenter de l'am√©liorer.

<img src="img/exp3/precision.png" width="350" height="300">
<img src="img/exp3/recall.png" width="350" height="300">

### Experiment n¬∞4 et n¬∞5 ([real_exp_13_yolo_m](https://app.picsellia.com/0192f6db-86b6-784c-80e6-163debb242d5/project/01936425-704a-7d93-b1bb-1b1641812ba4/experiment/0194e552-fd8a-7653-a191-b30dfbc1eb09/), [real_exp_14_yolo_m](https://app.picsellia.com/0192f6db-86b6-784c-80e6-163debb242d5/project/01936425-704a-7d93-b1bb-1b1641812ba4/experiment/0194e6dd-dae1-75cf-a3bd-bb0d53054008/))

#### Param√®tres de l'entrainement n¬∞4
- Mod√®le : experiment n¬∞3
- epochs : 100
- patience : 20
- Param√®tres par d√©faut

Les diff√©rentes loss pendant le training de l'experiment n¬∞3 :

| box_loss                                                   | cls_loss                                                   | dfl_loss                                                   |
|------------------------------------------------------------|------------------------------------------------------------|------------------------------------------------------------|
| <img src="img/exp4/box_loss.png" width="350" height="300"> | <img src="img/exp4/cls_loss.png" width="350" height="300"> | <img src="img/exp4/dfl_loss.png" width="350" height="300"> |  

<img src="img/exp4/conf_matrix.png" width="350" height="300"> 

#### Param√®tres de l'entrainement n¬∞5
- Mod√®le : experiment n¬∞4
- epochs : 100
- patience : 20
- Param√®tres par d√©faut

Les diff√©rentes loss pendant le training de l'experiment n¬∞5 : 

| box_loss                                                   | cls_loss                                                   | dfl_loss                                                   |
|------------------------------------------------------------|------------------------------------------------------------|------------------------------------------------------------|
| <img src="img/exp5/box_loss.png" width="350" height="300"> | <img src="img/exp5/cls_loss.png" width="350" height="300"> | <img src="img/exp5/dfl_loss.png" width="350" height="300"> |  

<img src="img/exp5/conf_matrix.png" width="350" height="300"> 


Les deux experiments ont √©t√© faites sur 100 epochs avec une patience de 20. L'experiment n¬∞4 a fait les 100 epochs mais 
l'experiment n¬∞5 n'a fait que 60. 
On voit que sur l'experiment n¬∞4, les loss commencent d√©j√† √† s'√©loigner et c'est encore plus marquant sur la n¬∞5.

Finalement le r√©sultat sur ces experiments n'est pas vraiment satisfaisant. 

On va tenter une nouvelle experiment depuis le mod√®le M de base en modifiant la learning rate pour limiter les variations 
au niveau des validation loss. Pour la learning rate finale, on peut la modifier l√©g√®rement car on voit que sur les 
training pr√©c√©dent, elles se stabilisaient vers la fin du training.

### R√©sum√© des experiments
<img src="img/schemas/test-part-schema.png" >

## Des r√©sultats int√©ressants

### Experiment n¬∞6 ([real_exp_15_yolo_m_lr](https://app.picsellia.com/0192f6db-86b6-784c-80e6-163debb242d5/project/01936425-704a-7d93-b1bb-1b1641812ba4/experiment/0194e726-a3fe-7ae3-a710-baf712db1ed0/))

#### Param√®tres de l'entrainement n¬∞6
- Mod√®le : YOLOv11-M
- epochs : 200
- patience : 20
- lr0 = 0.00179
- lrf = 0.01518

Les valeurs des learning rates proviennent d'un d√©but d'optimisation avec la m√©thode `model.tune()` de Ultralytics, bien 
que nous n'ayons plus les param√®tres exacts utilis√©s pour cette phase d'ajustement. Les r√©sultats obtenus semblent 
plut√¥t bon pour √™tre une base de travail.

<img src="img/exp6/tune_graph.png" width="500" height="300">

Le fait de baisser la learning rate a permis de stabiliser un peu plus les variations des validations loss

| box_loss                                                   | cls_loss                                                   | dfl_loss                                                   |
|------------------------------------------------------------|------------------------------------------------------------|------------------------------------------------------------|
| <img src="img/exp6/box_loss.png" width="350" height="300"> | <img src="img/exp6/cls_loss.png" width="350" height="300"> | <img src="img/exp6/dfl_loss.png" width="350" height="300"> |  

<img src="img/exp6/conf_matrix.png" width="350" height="300"> 
<img src="img/exp6/F1_curve.png" width="350" height="300">

Les premiers r√©sultats sont plut√¥t satisfaisants avec une fitness de 77.6%, le meilleur score obtenu jusqu'√† pr√©sent.

Cependant, le mod√®le rencontre des difficult√©s avec la reconnaissance des mikados et des capsules, souvent confondus 
avec l'arri√®re-plan. Une prochaine √©tape consisterait √† poursuivre l'entra√Ænement sur plus d'epochs et d'int√©grer des 
techniques de data augmentation pour am√©liorer ces d√©tections.


### Experiment n¬∞7 ([real_exp_16_yolo_m_augm](https://app.picsellia.com/0192f6db-86b6-784c-80e6-163debb242d5/project/01936425-704a-7d93-b1bb-1b1641812ba4/experiment/0194e7f9-6718-76eb-814f-bb28a78a81d5/))

#### Param√®tres de l'entrainement n¬∞7
- Mod√®le : experiment n¬∞6
- epochs : 100
- patience : 50
- lr0 = 0.000895
- lrf = 0.00759
- mixup = 0.3
- mosaic = 0.3

L'ajustement en divisant par 2 les learning rates vise √† √©viter d‚Äôeffacer les progr√®s du mod√®le. L'ajout de mixup et 
mosaic permet d'augmenter la complexit√© des images d'entra√Ænement, en combinant plusieurs images en une et en g√©n√©rant 
des mosa√Øques.

Les diff√©rentes loss pendant le training :

| box_loss                                                   | cls_loss                                                   | dfl_loss                                                   |
|------------------------------------------------------------|------------------------------------------------------------|------------------------------------------------------------|
| <img src="img/exp7/box_loss.png" width="350" height="300"> | <img src="img/exp7/cls_loss.png" width="350" height="300"> | <img src="img/exp7/dfl_loss.png" width="350" height="300"> |  


<img src="img/exp7/conf_matrix.png" width="350" height="300">

Les am√©liorations sont globalement l√©g√®res, sauf pour les Mikados, qui perdent 0.13 en score. 

| Classe         | Exp n¬∞6 | Exp n¬∞7 | Evolution |
|----------------|---------|---------|-----------|
| Mikado         | 1.0     | 0.87    | - 0.13    |  
| Kinder pingui  | 0.78    | 0.86    | + 0.08    |  
| Kinder country | 0.60    | 0.70    | + 0.10    |  
| Kinder tronky  | 0.80    | 0.78    | - 0.02    |  
| Tic Tac        | 0.95    | 0.95    | =         |  
| Sucette        | 0.72    | 0.75    | + 0.03    |  
| Capsule        | 0.56    | 0.56    | =         |  
| Pepito         | 0.77    | 0.80    | + 0.03    |  
| Bouteille      | 0.82    | 0.83    | + 0.01    |  
| Canette        | 0.76    | 0.74    | - 0.02    |  

| Experiment | Fitness | 
|------------|---------|
| exp 6      | 77.6 %  | 
| exp 7      | 78.4 %  |

Une prochaine experiment pourrait √™tre envisag√©e en r√©utilisant le mod√®le de l'experiment 6 avec d'autres param√®tres de 
data augmentation.

### Experiment n¬∞8 ([real_exp_17_yolo_m_augm](https://app.picsellia.com/0192f6db-86b6-784c-80e6-163debb242d5/project/01936425-704a-7d93-b1bb-1b1641812ba4/experiment/0194e9ad-af59-70aa-b3f6-ff9284c81521/))

#### Param√®tres de l'entrainement n¬∞8
- Mod√®le : experiment n¬∞6
- epochs : 30
- patience : 10
- lr0 = 0.000895
- lrf = 0.00759
- translate= 0.1
- mosaic = 0.1,
- scale=0.5, 
- shear=10, 
- flipud=0.5

Les diff√©rentes loss pendant le training :

| box_loss                                                   | cls_loss                                                   | dfl_loss                                                   |
|------------------------------------------------------------|------------------------------------------------------------|------------------------------------------------------------|
| <img src="img/exp8/box_loss.png" width="350" height="300"> | <img src="img/exp8/cls_loss.png" width="350" height="300"> | <img src="img/exp8/dfl_loss.png" width="350" height="300"> |  

<img src="img/exp8/conf_matrix.png" width="350" height="300">

| Classe         | Exp n¬∞6 | Exp n¬∞8 | Evolution |
|----------------|---------|---------|-----------|
| Mikado         | 1.0     | 1.0     | =         |  
| Kinder pingui  | 0.78    | 0.86    | + 0.08    |  
| Kinder country | 0.60    | 0.70    | + 0.10    |  
| Kinder tronky  | 0.80    | 0.78    | - 0.02    |  
| Tic Tac        | 0.95    | 0.95    | =         |  
| Sucette        | 0.72    | 0.76    | + 0.04    |  
| Capsule        | 0.56    | 0.69    | + 0.13    |  
| Pepito         | 0.77    | 0.73    | - 0.04    |  
| Bouteille      | 0.82    | 0.85    | + 0.03    |  
| Canette        | 0.76    | 0.79    | + 0.03    | 

| Experiment | Fitness | 
|------------|---------|
| exp 6      | 77.6 %  | 
| exp 7      | 78.4 %  |
| exp 8      | 81.1 %  |


Avec ces param√®tres, on obtient de bien meilleur r√©sultat. Certes, il y a des classes qui ont diminu√©, mais la diminution
est bien faible par rapport aux gains sur les autres classes.

On pourrait essayer une derni√®re experiment en augmentant les param√®tres de celle-ci et en supprimant la patience
pour voir ce que cela donne si l'on va au bout des 30 epochs sur le mod√®le de l'experiment 6.


### Experiment n¬∞9 ([real_exp_18_yolo_m_augm](https://app.picsellia.com/0192f6db-86b6-784c-80e6-163debb242d5/project/01936425-704a-7d93-b1bb-1b1641812ba4/experiment/0194e9ec-cbdd-78d9-9e68-6f235e19a0b0/))

#### Param√®tres de l'entrainement n¬∞9
- Mod√®le : experiment n¬∞6
- epochs : 30
- patience : 0
- lr0 = 0.000895
- lrf = 0.00759
- translate= 0.1
- mosaic = 0.1,
- scale=0.5, 
- shear=10, 
- flipud=0.5

<img src="img/exp9/conf_matrix.png" width="350" height="300">

| Classe         | Exp n¬∞6 | Exp n¬∞9 | Evolution |
|----------------|---------|---------|-----------|
| Mikado         | 1.0     | 0.87    | - 0.13    |  
| Kinder pingui  | 0.78    | 0.84    | + 0.06    |  
| Kinder country | 0.60    | 0.65    | + 0.05    |  
| Kinder tronky  | 0.80    | 0.78    | - 0.02    |  
| Tic Tac        | 0.95    | 0.84    | - 0.11    |  
| Sucette        | 0.72    | 0.69    | - 0.03    |  
| Capsule        | 0.56    | 0.59    | + 0.03    |  
| Pepito         | 0.77    | 0.76    | - 0.01    |  
| Bouteille      | 0.82    | 0.78    | - 0.04    |  
| Canette        | 0.76    | 0.72    | - 0.04    | 

| Experiment | Fitness | 
|------------|---------|
| exp 6      | 77.6 %  | 
| exp 7      | 78.4 %  |
| exp 8      | 81.1 %  |
| exp 9      | 75.2 %  |

Avec cette experiment, le mod√®le est bon que l'original.


### R√©sum√© des experiments
<img src="img/schemas/result-part-schema.png">

## Conclusion
Nous avons d√©cid√© de conserver le mod√®le de l‚Äôexp√©rimentation n¬∞8, qui offre les meilleurs r√©sultats obtenus jusqu‚Äô√† 
pr√©sent. Il serait possible de poursuivre le fine-tuning pour encore am√©liorer les performances, mais le mod√®le actuel 
est d√©j√† plut√¥t correct.

Une autre m√©thode aurait √©t√© d‚Äôutiliser `model.tune()` de Ultralytics de mani√®re plus pouss√©e pour rechercher 
automatiquement les meilleurs hyper-param√®tres. Nous avons test√© cette m√©thode, mais cette approche demande 
√©norm√©ment de ressources, ce qui n'√©tait pas envisageable dans notre cas (√† moins de louer 4 RTX 4090, mais bon ... üí∏üêÄ).

Finalement, partir des param√®tres par d√©faut propos√©s par Ultralytics, qui sont vraiment bon, et ajouter des data 
augmentations nous a permis d‚Äôobtenir un mod√®le aux performances plut√¥t correctes sans n√©cessiter un tuning automatique 
trop co√ªteux.

|                  | Lien                                                                                                                                                                   | 
|------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Meilleur mod√®le  | [model_latest](https://app.picsellia.com/0192f6db-86b6-784c-80e6-163debb242d5/model/01936429-42c2-7152-8cd1-ba068fa9d87a/version/0194e9b9-36a7-7580-ae8d-b307e8a03c0d) | 
| Autre bon mod√®le | [model_latest](https://app.picsellia.com/0192f6db-86b6-784c-80e6-163debb242d5/model/01936429-42c2-7152-8cd1-ba068fa9d87a/version/0194c29a-b7fc-709f-8a81-af438610aa38) | 

